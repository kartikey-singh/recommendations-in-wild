{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "import random\n",
    "import warnings\n",
    "import requests\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from requests_toolbelt.multipart.encoder import MultipartEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetPartTextFromAudio:\n",
    "    api_key = 'EB72E803F05E421E93E2'\n",
    "    \n",
    "    def __init__(self, wav_file_path):\n",
    "        self.wav_file_path = wav_file_path\n",
    "        \n",
    "    def send_request_for_audio_conversion(self):\n",
    "        multipart_data = MultipartEncoder(\n",
    "            fields={\n",
    "                    'filePath': ('file.wav', open(self.wav_file_path, 'rb')),\n",
    "                    'samplerate': '16000', \n",
    "                    'channel': '1',\n",
    "                    'normalize': 'yes'\n",
    "                   }\n",
    "            )\n",
    "\n",
    "        response = requests.post('https://apis.sentient.io/microservices/utility/audioprocessing/v0.1/getresults', \n",
    "                                 data=multipart_data, \n",
    "                                 headers={\n",
    "                                     'Content-Type': multipart_data.content_type,\n",
    "                                     'x-api-key': self.api_key\n",
    "                                 })\n",
    "        return response.json()\n",
    "\n",
    "\n",
    "    def send_request_for_speech_to_text_conversion(self, binary_wav_string):\n",
    "        payload = {\n",
    "            'model': 'news_parliament',\n",
    "            'wav_base64': binary_wav_string                                \n",
    "        }\n",
    "        payload_json = json.dumps(payload)\n",
    "        response = requests.post('https://apis.sentient.io/microservices/voice/asr/v0.1/getpredictions', \n",
    "                                 data=payload_json, \n",
    "                                 headers={\n",
    "                                     'content-type': 'application/json',\n",
    "                                     'x-api-key': self.api_key\n",
    "                                 })\n",
    "        return response.json()\n",
    "    \n",
    "    def get_text_from_response(self, speech_to_text_response):\n",
    "        response_text = \"\"\n",
    "        for speech_utterance in speech_to_text_response['results']:\n",
    "            response_text = response_text + speech_utterance['text']\n",
    "        return response_text   \n",
    "        \n",
    "    def process(self):\n",
    "        audio_conversion_response = self.send_request_for_audio_conversion()\n",
    "        speech_to_text_response = send_request_for_speech_to_text_conversion(audio_conversion_response['results']['AudioContent']) \n",
    "        return self.get_text_from_response(speech_to_text_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GetPartTextFromAudio('resources/music/3.mp3_outputs/spleeter/out001/vocals.wav').process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rev_ai import apiclient\n",
    "# client = apiclient.RevAiAPIClient(\"02TwQ2L4_koragMvDIEReVDmQDwF_Pzoy2JJaPjj1QPaxPEVX-H6lEz4JSh9dYsstFgBt-XZchG4UN8QSmwL3TeD3EM4w\")\n",
    "# job = client.submit_job_local_file('resources/music/1.mp3')\n",
    "# transcript_json = client.get_transcript_json(job.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo\n",
    "# Create a flask script to run as API, get word embeddings-> then cosine similarity and show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_stopword(x):\n",
    "#     return [y for y in x if y not in stopwords.words('english')]\n",
    "\n",
    "# def clean_text(text):\n",
    "#     '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "#     and remove words containing numbers.'''\n",
    "#     text = str(text).lower()\n",
    "#     text = text.replace('’','\\'')\n",
    "#     text = re.sub('\\[.*?\\]', '', text)\n",
    "#     text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "#     text = re.sub('<.*?>+', '', text)\n",
    "#     text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "#     text = re.sub('\\n', '', text)\n",
    "#     text = re.sub('\\w*\\d\\w*', '', text)\n",
    "#     text = re.sub('instagram.*', '', text)\n",
    "#     text = re.sub('piccom.*', '', text)\n",
    "#     text = re.sub('https|…|twitter|#|@|“|”|°', '', text)\n",
    "#     text = re.sub('mothers|day|happy|mothersday', '', text)\n",
    "#     text_list = remove_stopword(str(text).split())    \n",
    "#     return ' '.join(text_list)\n",
    "\n",
    "# df['cleaned_lyrics'] = df['seq'].apply(lambda x:clean_text(x))\n",
    "\n",
    "# df.to_csv('resources/dataset/cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('resources/dataset/cleaned.csv')\n",
    "# df = df.dropna()\n",
    "# df = df[['artist', 'song', 'cleaned_lyrics', 'label']]\n",
    "# df.to_csv('resources/dataset/cleaned.csv')\n",
    "# df[['artist', 'song']].to_csv('resources/dataset/lookup.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module_url = \"https://tfhub.dev/google/nnlm-en-dim128/2\"\n",
    "# embed = hub.KerasLayer(module_url)\n",
    "\n",
    "# arr = np.empty((0,128), int)\n",
    "\n",
    "# for index, x in  df['cleaned_lyrics'].items():\n",
    "#     arr = np.append(arr, embed([x]).numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create generate embed \n",
    "# getRecommendation -> upload file -> run script -> then sentinet get text -> read csv, generate embed -> cosine -> return list of songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('resources/dataset/embedding_lookup.npy', 'wb') as f:\n",
    "#     np.save(f, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('resources/dataset/embedding_lookup.npy', 'rb') as f:\n",
    "#     a1 = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = cosine_similarity(arr, a)\n",
    "c = np.argsort(b, axis=0)[::-1][:4]\n",
    "c = c.flatten()\n",
    "c = list(c)\n",
    "s = df.iloc[c,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
